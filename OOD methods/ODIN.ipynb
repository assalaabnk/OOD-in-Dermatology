{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ODIN"
      ],
      "metadata": {
        "id": "Ksh2Fk-dH2qy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hMQedxF5R5u3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIZp43R6vVH9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from tqdm import trange\n",
        "\n",
        "import keras.backend as K\n",
        "import cv2\n",
        "from odin import norm_perturbations\n",
        "from scipy.special import softmax\n",
        "\n",
        "\n",
        "from PIL import Image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ge2w_bqUOpcB"
      },
      "source": [
        "**Loading the pretrained DenseNet model :**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P71ii-fmZB9Z",
        "outputId": "904c9e32-ccd9-4cb3-e6eb-92e9ba7a5e42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Network...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/init_ops.py:94: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/init_ops.py:94: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/init_ops.py:94: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/normalization/batch_normalization.py:883: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Done.\n"
          ]
        }
      ],
      "source": [
        "print ('Loading Network...')\n",
        "model_path = '../Models/my_model_densenet.h5'\n",
        "densenet_model  = tf.keras.models.load_model(model_path)\n",
        "print(' Done.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYQ4a09ZmhVu"
      },
      "source": [
        "# Image generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLiQGIHEo_x7",
        "outputId": "a18d624c-b4bc-42aa-a796-98c2ba1ee839"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training using the following parameters:\n",
            "augment: True\n",
            "batch_size: 40\n",
            "checkpoint_frequency: 1000\n",
            "dataset_root: /usr/xtmp/hannah/segkeras/nn-isic2019/dataset/\n",
            "decay_start_iteration: 15000\n",
            "detailed_logs: False\n",
            "early_stop_patience: 8\n",
            "experiment_root: FL_Aug_MEL\n",
            "gpu_device: 0\n",
            "heavy_augment: False\n",
            "init_epoch: 0\n",
            "initial_checkpoint: None\n",
            "is_train: 1\n",
            "learning_rate: 1e-06\n",
            "load_weights: None\n",
            "loading_threads: 8\n",
            "loss_type: 1\n",
            "margin: soft\n",
            "num_classes: 7\n",
            "num_epochs: 25\n",
            "num_gpus: 1\n",
            "resume: False\n",
            "sizeH: 224\n",
            "sizeW: 224\n",
            "skip_class: MEL\n",
            "train_iterations: 25000\n"
          ]
        }
      ],
      "source": [
        "from argument_parser import myParser\n",
        "args = myParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0N-pc_JuKAi",
        "outputId": "71343565-783d-4ff1-f0bf-cf4d3a88a391"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Data Generators...\n",
            "Loading Testing Dataset...\n",
            "   Done.\n"
          ]
        }
      ],
      "source": [
        "#Fitz Darker only\n",
        "from data_generators import fitzpatrick17kImageDataset\n",
        "## Loading Data Generators\n",
        "ROOT = '/fitzpatrick 17k /'\n",
        "\n",
        "print('Loading Data Generators...')\n",
        "\n",
        "args.num_classes = 3\n",
        "args.sizeW = 224\n",
        "args.sizeH = 224\n",
        "args.dataset_root = ROOT\n",
        "args.is_train = 2 # Validation Set\n",
        "Testing_generator_FST_V-VI = fitzpatrick17kImageDataset(args)\n",
        "\n",
        "print('   Done.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgsqykNOnhKr",
        "outputId": "9fbe0225-2ecf-49bb-c5b9-64580abfae39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Data Generators...\n",
            "Loading Testing Dataset...\n",
            "   Done.\n"
          ]
        }
      ],
      "source": [
        "#Fitz Lighter only\n",
        "from data_generators import fitzpatrick17kImageDataset\n",
        "## Loading Data Generators\n",
        "ROOT = '/fitzpatrick 17k /'\n",
        "\n",
        "print('Loading Data Generators...')\n",
        "\n",
        "args.num_classes = 3\n",
        "args.sizeW = 224\n",
        "args.sizeH = 224\n",
        "args.dataset_root = ROOT\n",
        "args.is_train = 2 # Validation Set  change the condition on common.py before running\n",
        "Testing_generator_FST_I-IV = fitzpatrick17kImageDataset(args)\n",
        "\n",
        "print('   Done.')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLQGdhPsn2n2",
        "outputId": "5e09e531-f89e-4df3-cc29-85fe4d453a7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Data Generators...\n",
            "Loading Validation Dataset...\n",
            "   Done.\n"
          ]
        }
      ],
      "source": [
        "#Fitz ALL images\n",
        "from data_generators import fitzpatrick17kImageDataset\n",
        "## Loading Data Generators\n",
        "ROOT = '/fitzpatrick 17k /'\n",
        "\n",
        "print('Loading Data Generators...')\n",
        "\n",
        "args.num_classes = 3\n",
        "args.sizeW = 224\n",
        "args.sizeH = 224\n",
        "args.dataset_root = ROOT\n",
        "args.is_train = 0 # Validation Set\n",
        "Testing_generator_ALL = fitzpatrick17kImageDataset(args)\n",
        "\n",
        "print('   Done.')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEZd-bpRa0yB",
        "outputId": "8c821927-1ed2-413c-ad66-6b96110870bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Data Generators...\n",
            "class_names:['MEL', 'NV', 'BCC', 'AK', 'BKL', 'SCC']\n",
            "skip_class:['DF', 'VASC']\n",
            "Loading Testing Dataset...\n",
            "   Done.\n"
          ]
        }
      ],
      "source": [
        "#ISIC\n",
        "from data_generators import ISICImageDataset\n",
        "## Loading Data Generators\n",
        "ROOT = '/ISIC_2019_Training_Input/'\n",
        "\n",
        "print('Loading Data Generators...')\n",
        "args.is_train = 2 # Training Set\n",
        "args.num_classes = 6\n",
        "args.sizeW = 224\n",
        "args.sizeH = 224\n",
        "args.dataset_root = ROOT\n",
        "args.is_train = 2 # Validation Set\n",
        "Validation_generator = ISICImageDataset(args)\n",
        "print('   Done.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwgcrcDHCL4V"
      },
      "outputs": [],
      "source": [
        "def compute_baseline_softmax_scores(model, generator_in, generator_out):\n",
        "    \"\"\"\n",
        "    Calculate the base confidence of the output, no perturbation added here, no temperature scaling used.\n",
        "    Directly copy the original prediction results.\n",
        "    \"\"\"\n",
        "    print('Begin to compute baseline softmax scores')\n",
        "    distributions = ['In', 'Out']\n",
        "\n",
        "\n",
        "    for dist in distributions:\n",
        "        if dist == 'In':\n",
        "            generator = generator_in\n",
        "        elif dist == 'Out':\n",
        "            generator = generator_out\n",
        "\n",
        "        with open(\"./densenet121_Base_{}.txt\".format(dist), 'w') as f:\n",
        "            for i in range(len(generator.fids)):\n",
        "                # print('thisFid: '+str(generator.fids[i]))\n",
        "                thisImg = Image.open(generator.fids[i]+'.jpg').convert(\"RGB\")\n",
        "                thisImg = np.expand_dims(np.asarray(thisImg.resize((224,224)))/255, axis =0)\n",
        "                softmax_probs = model.predict(thisImg)\n",
        "                softmax_score = np.max(softmax_probs)\n",
        "                f.write(\"{}\\n\".format(softmax_score))\n",
        "        f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jF1g8NvqxKJe"
      },
      "outputs": [],
      "source": [
        "def get_perturbation_helper_func(model, temperature, num_classes):\n",
        "    \"\"\" Return Keras functions for calculating perturbations. \"\"\"\n",
        "    # Compute loss based on the second last layer's output and temperature scaling\n",
        "    dense_pred_layer_output = model.get_layer('dense_4').output\n",
        "    scaled_dense_pred_output = dense_pred_layer_output / temperature\n",
        "\n",
        "    print(dense_pred_layer_output)\n",
        "    print(scaled_dense_pred_output)\n",
        "\n",
        "    print(K.argmax(model.outputs))\n",
        "\n",
        "    label_tensor = K.one_hot(K.argmax(model.outputs), 1)\n",
        "    tf.print(label_tensor)\n",
        "    loss = K.sparse_categorical_crossentropy(label_tensor, scaled_dense_pred_output, from_logits=True)\n",
        "    grad_loss = K.gradients(loss, model.inputs)\n",
        "\n",
        "    compute_perturbations = K.function(model.inputs + [K.learning_phase()], grad_loss)\n",
        "    get_scaled_dense_pred_output = K.function(model.inputs + [K.learning_phase()], [scaled_dense_pred_output])\n",
        "\n",
        "    return compute_perturbations, get_scaled_dense_pred_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JU_pImXqY91M"
      },
      "source": [
        "# Find the best parameters :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CO6-96wbdrfw"
      },
      "outputs": [],
      "source": [
        "def compute_odin_softmax_scores(model, generator_in, generator_out, num_classes = 6, batch_size = 1):\n",
        "    distributions = ['In', 'Out']\n",
        "\n",
        "    # This file is used for recording what parameter combinations were already computed.\n",
        "    progress_file = os.path.join('Done.txt')\n",
        "    done_set = set()\n",
        "    if os.path.exists(progress_file):\n",
        "        with open(progress_file, 'r') as f:\n",
        "            done_set = set(line.rstrip('\\n') for line in f)\n",
        "\n",
        "    # ODIN parameters\n",
        "\n",
        "    model_name = 'DenseNet201'\n",
        "    #Grid Search\n",
        "    temperatures = [1000, 500, 200, 100, 50, 20, 10, 5, 2, 1]\n",
        "\n",
        "    magnitudes = np.round(np.arange(0, 0.0041, 0.0002), 4)\n",
        "\n",
        "    need_norm_perturbations = 1\n",
        "\n",
        "\n",
        "\n",
        "#     model_param_map = get_transfer_model_param_map()\n",
        "    image_data_format = K.image_data_format()\n",
        "    learning_phase = 0 # 0 = test, 1 = train\n",
        "\n",
        "\n",
        "\n",
        "    for temperature in temperatures:\n",
        "        compute_perturbations, get_scaled_dense_pred_output = get_perturbation_helper_func(model, temperature, num_classes)\n",
        "\n",
        "        for magnitude in magnitudes:\n",
        "            for dist in distributions:\n",
        "                # Skip if the parameter combination has done\n",
        "                param_comb_id = \"{}, {}, {}\".format( dist, temperature, magnitude)\n",
        "                if param_comb_id in done_set:\n",
        "                    print('Skip ', param_comb_id)\n",
        "                    continue\n",
        "\n",
        "                if dist == 'In':\n",
        "                    generator = generator_in\n",
        "                elif dist == 'Out':\n",
        "                    generator = generator_out\n",
        "\n",
        "                print(\"\\n===== Temperature: {}, Magnitude: {}, {}-Distribution =====\".format(temperature, magnitude, dist))\n",
        "\n",
        "                try:\n",
        "                    f = open(\"./densenet121_ODIN_{}_{}_{}.txt\".format(temperature, magnitude,dist), 'w')\n",
        "                    for i in trange(len(generator.fids)):\n",
        "                        thisFid = generator.fids[i]\n",
        "                        images = np.expand_dims(cv2.resize(np.array(Image.open(thisFid+'.jpg').convert(\"RGB\"))/255, (224,224), interpolation=cv2.INTER_LINEAR), axis = 0)\n",
        "\n",
        "                        perturbations = compute_perturbations([images, learning_phase])[0]\n",
        "                    # Get sign of perturbations\n",
        "                        perturbations = np.sign(perturbations)\n",
        "\n",
        "                    # Normalize the perturbations to the same space of image\n",
        "                    # https://github.com/facebookresearch/odin/issues/5\n",
        "                    # Perturbations divided by ISIC Training Set STD\n",
        "                        if need_norm_perturbations:\n",
        "                            perturbations = norm_perturbations(perturbations, image_data_format)\n",
        "\n",
        "                    # Add perturbations to images\n",
        "                        perturbative_images = images - magnitude * perturbations\n",
        "\n",
        "                    # Calculate the confidence after adding perturbations\n",
        "                        dense_pred_outputs = get_scaled_dense_pred_output([perturbative_images, learning_phase])[0]\n",
        "                        softmax_probs = softmax(dense_pred_outputs)\n",
        "                        softmax_scores = np.max(softmax_probs, axis=-1)\n",
        "\n",
        "                        for s in softmax_scores:\n",
        "                            f.write(\"{}\\n\".format(s))\n",
        "                    f.close()\n",
        "\n",
        "                    with open(progress_file, 'a') as f_done:\n",
        "                        f_done.write(\"{}\\n\".format(param_comb_id))\n",
        "\n",
        "                except FileNotFoundError:\n",
        "                    # Handle the \"File not found\" error\n",
        "                    print(f\"File not found for {param_comb_id}. Skipping...\")\n",
        "                    continue\n",
        "                last_processed_combination = param_comb_id\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiCMEp-45Q93"
      },
      "outputs": [],
      "source": [
        "from odin import norm_perturbations\n",
        "from scipy.special import softmax\n",
        "\n",
        "def compute_odin_softmax_scores(model, generator_in, generator_out, num_classes=6, batch_size=1):\n",
        "    distributions = ['In', 'Out']\n",
        "\n",
        "    # This file is used for recording what parameter combinations were already computed.\n",
        "    progress_file = os.path.join('Done.txt')\n",
        "    done_set = set()\n",
        "    if os.path.exists(progress_file):\n",
        "        with open(progress_file, 'r') as f:\n",
        "            done_set = set(line.rstrip('\\n') for line in f)\n",
        "\n",
        "    # ODIN parameters\n",
        "    model_name = 'DenseNet201'\n",
        "    temperatures = [1000, 500, 200, 100, 50, 20, 10, 5, 2, 1]\n",
        "    #temperatures 200\n",
        "\n",
        "    magnitudes = np.round(np.arange(0.0002, 0.0041, 0.0002), 4)\n",
        "    #magnitudes = np.round([0.0002, 0.0041], 4)\n",
        "    need_norm_perturbations = 1\n",
        "    image_data_format = K.image_data_format()\n",
        "    learning_phase = 0  # 0 = test, 1 = train\n",
        "\n",
        "    for temperature in temperatures:\n",
        "        compute_perturbations, get_scaled_dense_pred_output = get_perturbation_helper_func(model, temperature, num_classes)\n",
        "\n",
        "        for magnitude in magnitudes:\n",
        "            for dist in distributions:\n",
        "                # Skip if the parameter combination has done\n",
        "                param_comb_id = \"{}, {}, {}\".format(dist, temperature, magnitude)\n",
        "                if param_comb_id in done_set:\n",
        "                    print('Skip ', param_comb_id)\n",
        "                    continue\n",
        "\n",
        "                if dist == 'In':\n",
        "                    generator = generator_in\n",
        "                elif dist == 'Out':\n",
        "                    generator = generator_out\n",
        "\n",
        "                print(\"\\n===== Temperature: {}, Magnitude: {}, {}-Distribution =====\".format(temperature, magnitude, dist))\n",
        "\n",
        "                # Check if the output file already exists, and if it does, skip processing\n",
        "                output_file_path = \"./densenet121_ODIN_{}_{}_{}.txt\".format(temperature, magnitude, dist)\n",
        "                if os.path.exists(output_file_path):\n",
        "                    print(f\"Output file {output_file_path} already exists. Skipping...\")\n",
        "                    continue\n",
        "\n",
        "                try:\n",
        "                    f = open(output_file_path, 'w')\n",
        "                    for i in trange(len(generator.fids)):\n",
        "                        thisFid = generator.fids[i]\n",
        "                        images = np.expand_dims(cv2.resize(np.array(Image.open(thisFid + '.jpg').convert(\"RGB\")) / 255,\n",
        "                                                           (224, 224), interpolation=cv2.INTER_LINEAR), axis=0)\n",
        "\n",
        "                        perturbations = compute_perturbations([images, learning_phase])[0]\n",
        "                        perturbations = np.sign(perturbations)\n",
        "\n",
        "                        if need_norm_perturbations:\n",
        "                            perturbations = norm_perturbations(perturbations, image_data_format)\n",
        "\n",
        "                        perturbative_images = images - magnitude * perturbations\n",
        "\n",
        "                        dense_pred_outputs = get_scaled_dense_pred_output([perturbative_images, learning_phase])[0]\n",
        "                        softmax_probs = softmax(dense_pred_outputs)\n",
        "                        softmax_scores = np.max(softmax_probs, axis=-1)\n",
        "\n",
        "                        for s in softmax_scores:\n",
        "                            f.write(\"{}\\n\".format(s))\n",
        "                    f.close()\n",
        "\n",
        "                    with open(progress_file, 'a') as f_done:\n",
        "                        f_done.write(\"{}\\n\".format(param_comb_id))\n",
        "\n",
        "                except Exception as e:\n",
        "                    # Handle any exceptions that might occur during file processing\n",
        "                    print(f\"An error occurred for {param_comb_id}: {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "                last_processed_combination = param_comb_id\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bo6hTeBnISxW"
      },
      "outputs": [],
      "source": [
        "compute_odin_softmax_scores(densenet_model, Validation_generator, Testing_generator_FST_V-VI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bl1-m5KaGfLt"
      },
      "outputs": [],
      "source": [
        "compute_odin_softmax_scores(densenet_model, Validation_generator, Testing_generator_FST_I-IV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwoAjwgFGfLu"
      },
      "outputs": [],
      "source": [
        "compute_odin_softmax_scores(densenet_model, Validation_generator, Testing_generator_ALL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zQEm9jgV-dc"
      },
      "outputs": [],
      "source": [
        "#testing the subset of parameters\n",
        "\n",
        "\n",
        "need_norm_perturbations = 1\n",
        "best_auroc = 0.0\n",
        "best_auroc_params = None\n",
        "lowest_fpr = float('inf')\n",
        "lowest_fpr_params = None\n",
        "\n",
        "\n",
        "#We want to loop over all the saved scores\n",
        "In_scores_files =\"/Models/ODIN/Saved scores/In\"\n",
        "Out_scores_files = \"/Models/ODIN/Saved scores/Out\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "in_dist_file=\"densenet121_ODIN_{}_{}_In.txt\".format(temperature, magnitude)\n",
        "out_dist_file=\"densenet121_ODIN_{}_{}_Out.txt\".format(temperature, magnitude)\n",
        "\n",
        "\n",
        "\n",
        " # Calculate AUROC\n",
        "auroc_value = auroc(in_dist_file=  , out_dist_file=out_dist_file)\n",
        "\n",
        "                    # Calculate FPR\n",
        "tpr, fpr = get_tpr_and_fpr(scores_in_test, scores_out_test, delta)\n",
        "\n",
        "                    # Update best AUROC and FPR if necessary\n",
        "if auroc_value > best_auroc:\n",
        "   best_auroc = auroc_value\n",
        "   best_auroc_params = (temperature, magnitude, dist)\n",
        "\n",
        "if fpr < lowest_fpr:\n",
        "   lowest_fpr = fpr\n",
        "   lowest_fpr_params = (temperature, magnitude, dist)\n",
        "\n",
        "print(\"Best AUROC: {:.4f}, Parameters: Temperature={}, Magnitude={}, Distribution={}\"\n",
        "      .format(best_auroc, *best_auroc_params))\n",
        "\n",
        "    # Print the lowest FPR and corresponding parameters\n",
        "print(\"Lowest FPR: {:.4f}, Parameters: Temperature={}, Magnitude={}, Distribution={}\"\n",
        "      .format(lowest_fpr, *lowest_fpr_params))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQNrE1jwuZKO",
        "outputId": "f9e26abf-fb90-40e4-d163-0900c3066e4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor(\"dense_4/BiasAdd:0\", shape=(?, 6), dtype=float32)\n",
            "Tensor(\"truediv:0\", shape=(?, 6), dtype=float32)\n",
            "Tensor(\"ArgMax:0\", shape=(1, ?), dtype=int64)\n",
            "Skip  In, 1000, 0.0\n",
            "\n",
            "===== Temperature: 1000, Magnitude: 0.0, Out-Distribution =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1318/1318 [27:31<00:00,  1.25s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== Temperature: 1000, Magnitude: 0.0002, In-Distribution =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2495/2495 [29:22<00:00,  1.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== Temperature: 1000, Magnitude: 0.0002, Out-Distribution =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1318/1318 [15:27<00:00,  1.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== Temperature: 1000, Magnitude: 0.0004, In-Distribution =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2495/2495 [29:31<00:00,  1.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== Temperature: 1000, Magnitude: 0.0004, Out-Distribution =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1318/1318 [15:33<00:00,  1.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== Temperature: 1000, Magnitude: 0.0006, In-Distribution =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2495/2495 [30:08<00:00,  1.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== Temperature: 1000, Magnitude: 0.0006, Out-Distribution =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1318/1318 [15:52<00:00,  1.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== Temperature: 1000, Magnitude: 0.0008, In-Distribution =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2495/2495 [29:59<00:00,  1.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== Temperature: 1000, Magnitude: 0.0008, Out-Distribution =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1318/1318 [15:45<00:00,  1.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== Temperature: 1000, Magnitude: 0.001, In-Distribution =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2495/2495 [30:18<00:00,  1.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== Temperature: 1000, Magnitude: 0.001, Out-Distribution =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1318/1318 [15:37<00:00,  1.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== Temperature: 1000, Magnitude: 0.0012, In-Distribution =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2495/2495 [30:37<00:00,  1.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== Temperature: 1000, Magnitude: 0.0012, Out-Distribution =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1318/1318 [15:46<00:00,  1.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== Temperature: 1000, Magnitude: 0.0014, In-Distribution =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2495/2495 [30:12<00:00,  1.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== Temperature: 1000, Magnitude: 0.0014, Out-Distribution =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1318/1318 [15:34<00:00,  1.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== Temperature: 1000, Magnitude: 0.0016, In-Distribution =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 41%|████      | 1013/2495 [12:01<18:12,  1.36it/s]"
          ]
        }
      ],
      "source": [
        "compute_odin_softmax_scores(densenet_model,Validation_generator, Testing_generator_FST_V-VI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvbhYACYGfLw"
      },
      "outputs": [],
      "source": [
        "compute_odin_softmax_scores(densenet_model,Validation_generator, Testing_generator_FST_I-IV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_9G5PkOI9AF"
      },
      "outputs": [],
      "source": [
        "from scipy.special import softmax\n",
        "from tqdm import trange\n",
        "\n",
        "# ODIN parameters\n",
        "#temperatures = [1000, 500, 200, 100, 50, 20, 10, 5, 2, 1]\n",
        "#magnitudes = np.round(np.arange(0, 0.0041, 0.0002), 4)\n",
        "optimal_temperature = 200\n",
        "optimal_magnitude = 0.0002\n",
        "optimal_delta = 0.90385\n",
        "\n",
        "\n",
        "def compute_odin_softmax_scores (model, generator_in, generator_out, num_classes=6, batch_size=1):\n",
        "    distributions = ['In', 'Out']\n",
        "\n",
        "    # Specify the desired starting magnitude and temperature\n",
        "    start_magnitude = 0.0008\n",
        "    start_temperature = 1000\n",
        "\n",
        "    # Find the indices for the desired magnitude and temperature\n",
        "    start_magnitude_idx = np.where(magnitudes == start_magnitude)[0][0]\n",
        "    start_temperature_idx = temperatures.index(start_temperature)\n",
        "\n",
        "    # This file is used for recording what parameter combinations were already computed.\n",
        "    progress_file = os.path.join('Done.txt')\n",
        "    done_set = set()\n",
        "    if os.path.exists(progress_file):\n",
        "        with open(progress_file, 'r') as f:\n",
        "            done_set = set(line.rstrip('\\n') for line in f)\n",
        "\n",
        "    image_data_format = K.image_data_format()\n",
        "    learning_phase = 0  # 0 = test, 1 = train\n",
        "\n",
        "    need_norm_perturbations = 1\n",
        "\n",
        "    for temperature_idx, temperature in enumerate(temperatures[start_temperature_idx:]):\n",
        "\n",
        "        if temperature_idx == 0:\n",
        "            magnitude_start_idx = start_magnitude_idx\n",
        "        else:\n",
        "            magnitude_start_idx = 0\n",
        "\n",
        "        compute_perturbations, get_scaled_dense_pred_output = get_perturbation_helper_func(model, temperature, num_classes)\n",
        "\n",
        "        for magnitude_idx, magnitude in enumerate(magnitudes[magnitude_start_idx:]):\n",
        "            for dist in distributions:\n",
        "                # Skip if the parameter combination has been done\n",
        "                param_comb_id = \"{}, {}, {}\".format(dist, temperature, magnitude)\n",
        "                if param_comb_id in done_set:\n",
        "                    print('Skip ', param_comb_id)\n",
        "                    continue\n",
        "\n",
        "                if dist == 'In':\n",
        "                    generator = generator_in\n",
        "                elif dist == 'Out':\n",
        "                    generator = generator_out\n",
        "\n",
        "                print(\"\\n===== Temperature: {}, Magnitude: {}, {}-Distribution =====\".format(temperature, magnitude, dist))\n",
        "\n",
        "                f = open(\"./densenet121_ODIN_{}_{}_{}.txt\".format(temperature, magnitude, dist), 'w')\n",
        "\n",
        "                # Start from the beginning\n",
        "                for i in trange(len(generator.fids)):\n",
        "                    try:\n",
        "                        thisFid = generator.fids[i]\n",
        "                        images = np.expand_dims(\n",
        "                            cv2.resize(np.array(Image.open(thisFid + '.jpg').convert(\"RGB\")) / 255, (224, 224),\n",
        "                                       interpolation=cv2.INTER_LINEAR), axis=0)\n",
        "\n",
        "                        perturbations = compute_perturbations([images, learning_phase])[0]\n",
        "                        # Get the sign of perturbations\n",
        "                        perturbations = np.sign(perturbations)\n",
        "\n",
        "                        # Normalize the perturbations to the same space of the image\n",
        "                        if need_norm_perturbations:\n",
        "                            perturbations = norm_perturbations(perturbations, image_data_format)\n",
        "\n",
        "                        # Add perturbations to images\n",
        "                        perturbative_images = images - magnitude * perturbations\n",
        "\n",
        "                        # Calculate the confidence after adding perturbations\n",
        "                        dense_pred_outputs = get_scaled_dense_pred_output([perturbative_images, learning_phase])[0]\n",
        "                        softmax_probs = softmax(dense_pred_outputs)\n",
        "                        softmax_scores = np.max(softmax_probs, axis=-1)\n",
        "                        for s in softmax_scores:\n",
        "                            f.write(\"{}\\n\".format(s))\n",
        "                    except FileNotFoundError:\n",
        "                        print(f\"File not found for index {i}. Continuing...\")\n",
        "                        continue\n",
        "\n",
        "                f.close()\n",
        "\n",
        "                with open(progress_file, 'a') as f_done:\n",
        "                    f_done.write(\"{}\\n\".format(param_comb_id))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ql0mrBzDTuTt"
      },
      "source": [
        "## Setting the optimal parameters :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWFXBuxbbANq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import keras.backend as K\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from odin import norm_perturbations\n",
        "from odin import get_tpr_and_fpr, auroc\n",
        "from scipy.special import softmax\n",
        "from tqdm import trange\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Optimal ODIN Parameters\n",
        "optimal_temperature = 200\n",
        "optimal_magnitude = 0.0002\n",
        "optimal_delta = 0.90385\n",
        "\n",
        "def compute_odin_parameters_and_metrics(model, generator_in, generator_out, num_classes=6, batch_size=1):\n",
        "    distributions = ['In', 'Out']\n",
        "    compute_perturbations, get_scaled_dense_pred_output = get_perturbation_helper_func(model, optimal_temperature, num_classes)\n",
        "\n",
        "    # This file is used for recording what parameter combinations were already computed.\n",
        "    progress_file = os.path.join('Done.txt')\n",
        "    done_set = set()\n",
        "    if os.path.exists(progress_file):\n",
        "        with open(progress_file, 'r') as f:\n",
        "            done_set = set(line.rstrip('\\n') for line in f)\n",
        "\n",
        "    image_data_format = K.image_data_format()\n",
        "    learning_phase = 0  # 0 = test, 1 = train\n",
        "\n",
        "    need_norm_perturbations = 1\n",
        "\n",
        "    # Initialize variables to store metrics\n",
        "    auroc_max = -1  # Initialize AUROC to a very low value\n",
        "    fpr_min = 1     # Initialize FPR to a very high value\n",
        "    odinparam_auroc_max = None\n",
        "    odinparam_fpr_min = None\n",
        "\n",
        "    for dist in distributions:\n",
        "        for magnitude in [optimal_magnitude]:\n",
        "            # Skip if the parameter combination has been done\n",
        "            param_comb_id = \"{}, {}, {}\".format(dist, optimal_temperature, magnitude)\n",
        "            if param_comb_id in done_set:\n",
        "                print('Skip ', param_comb_id)\n",
        "                continue\n",
        "\n",
        "            if dist == 'In':\n",
        "                generator = generator_in\n",
        "            elif dist == 'Out':\n",
        "                generator = generator_out\n",
        "\n",
        "            print(\"\\n===== Temperature: {}, Magnitude: {}, {}-Distribution =====\".format(optimal_temperature, magnitude, dist))\n",
        "\n",
        "            f = open(\"./densenet121_ODIN_{}_{}_{}.txt\".format(optimal_temperature, magnitude, dist), 'w')\n",
        "\n",
        "            # Start from the beginning\n",
        "            for i in trange(len(generator.fids)):\n",
        "                try:\n",
        "                    thisFid = generator.fids[i]\n",
        "                    images = np.expand_dims(\n",
        "                        cv2.resize(np.array(Image.open(thisFid + '.jpg').convert(\"RGB\")) / 255, (224, 224),\n",
        "                                   interpolation=cv2.INTER_LINEAR), axis=0)\n",
        "\n",
        "                    perturbations = compute_perturbations([images, learning_phase])[0]\n",
        "                    # Get the sign of perturbations\n",
        "                    perturbations = np.sign(perturbations)\n",
        "\n",
        "                    # Normalize the perturbations to the same space of the image\n",
        "                    if need_norm_perturbations:\n",
        "                        perturbations = norm_perturbations(perturbations, image_data_format)\n",
        "\n",
        "                    # Add perturbations to images\n",
        "                    perturbative_images = images - magnitude * perturbations\n",
        "\n",
        "                    # Calculate the confidence after adding perturbations\n",
        "                    dense_pred_outputs = get_scaled_dense_pred_output([perturbative_images, learning_phase])[0]\n",
        "                    softmax_probs = softmax(dense_pred_outputs)\n",
        "                    softmax_scores = np.max(softmax_probs, axis=-1)\n",
        "                    for s in softmax_scores:\n",
        "                        f.write(\"{}\\n\".format(s))\n",
        "                except FileNotFoundError:\n",
        "                    print(f\"File not found for index {i}. Continuing...\")\n",
        "                    continue\n",
        "\n",
        "            f.close()\n",
        "\n",
        "            with open(progress_file, 'a') as f_done:\n",
        "                f_done.write(\"{}\\n\".format(param_comb_id))\n",
        "\n",
        "\n",
        "# Call the function to compute ODIN parameters and metrics\n",
        "#compute_odin_parameters_and_metrics(densenet_model, Validation_generator, Testing_generator_lighter_only)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_FSBBS6upRo"
      },
      "outputs": [],
      "source": [
        "from scipy.special import softmax\n",
        "from tqdm import trange\n",
        "\n",
        "# Fixed ODIN Parameters\n",
        "#optimal_temperature = 2\n",
        "#optimal_magnitude = 0.0002\n",
        "\n",
        "optimal_temperature = 200\n",
        "optimal_magnitude = 0.0002\n",
        "\n",
        "def compute_odin_softmax_scores_fixed(model, generator_in, generator_out, num_classes=6, batch_size=1):\n",
        "    distributions = ['Out']\n",
        "    compute_perturbations, get_scaled_dense_pred_output = get_perturbation_helper_func(model, optimal_temperature, num_classes)\n",
        "\n",
        "    # This file is used for recording what parameter combinations were already computed.\n",
        "    progress_file = os.path.join('Done.txt')\n",
        "    done_set = set()\n",
        "    if os.path.exists(progress_file):\n",
        "        with open(progress_file, 'r') as f:\n",
        "            done_set = set(line.rstrip('\\n') for line in f)\n",
        "\n",
        "    image_data_format = K.image_data_format()\n",
        "    learning_phase = 0  # 0 = test, 1 = train\n",
        "    need_norm_perturbations = 1\n",
        "\n",
        "    for dist in distributions:\n",
        "        param_comb_id = \"{}, {}, {}\".format(dist, optimal_temperature, optimal_magnitude)\n",
        "        if param_comb_id in done_set:\n",
        "            print('Skip ', param_comb_id)\n",
        "            continue\n",
        "\n",
        "        if dist == 'In':\n",
        "            generator = generator_in\n",
        "        elif dist == 'Out':\n",
        "            generator = generator_out\n",
        "\n",
        "        print(\"\\n===== Temperature: {}, Magnitude: {}, {}-Distribution =====\".format(optimal_temperature, optimal_magnitude, dist))\n",
        "\n",
        "        f = open(\"./densenet121_ODIN_{}_{}_{}.txt\".format(optimal_temperature, optimal_magnitude, dist), 'w')\n",
        "\n",
        "        for i in trange(len(generator.fids)):\n",
        "            try:\n",
        "                thisFid = generator.fids[i]\n",
        "                images = np.expand_dims(\n",
        "                    cv2.resize(np.array(Image.open(thisFid + '.jpg').convert(\"RGB\")) / 255, (224, 224),\n",
        "                               interpolation=cv2.INTER_LINEAR), axis=0)\n",
        "\n",
        "                perturbations = compute_perturbations([images, learning_phase])[0]\n",
        "                # Get sign of perturbations\n",
        "                perturbations = np.sign(perturbations)\n",
        "\n",
        "                # Normalize the perturbations to the same space of image\n",
        "                if need_norm_perturbations:\n",
        "                    perturbations = norm_perturbations(perturbations, image_data_format)\n",
        "\n",
        "                # Add perturbations to images\n",
        "                perturbative_images = images - optimal_magnitude * perturbations\n",
        "\n",
        "                # Calculate the confidence after adding perturbations\n",
        "                dense_pred_outputs = get_scaled_dense_pred_output([perturbative_images, learning_phase])[0]\n",
        "                softmax_probs = softmax(dense_pred_outputs)\n",
        "                softmax_scores = np.max(softmax_probs, axis=-1)\n",
        "                for s in softmax_scores:\n",
        "                    f.write(\"{}\\n\".format(s))\n",
        "            except FileNotFoundError:\n",
        "                print(f\"File not found for index {i}. Continuing...\")\n",
        "                continue\n",
        "\n",
        "        f.close()\n",
        "\n",
        "        with open(progress_file, 'a') as f_done:\n",
        "            f_done.write(\"{}\\n\".format(param_comb_id))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3pmPu4Xievy"
      },
      "source": [
        "## ODIN scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7R9EYh9heSp",
        "outputId": "43f817e0-b7f6-453d-daa5-1eaf070a1af1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor(\"dense_4/BiasAdd:0\", shape=(?, 6), dtype=float32)\n",
            "Tensor(\"truediv_6:0\", shape=(?, 6), dtype=float32)\n",
            "Tensor(\"ArgMax_12:0\", shape=(1, ?), dtype=int64)\n",
            "\n",
            "===== Temperature: 200, Magnitude: 0.0002, Out-Distribution =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1318/1318 [15:24<00:00,  1.43it/s]\n"
          ]
        }
      ],
      "source": [
        "compute_odin_softmax_scores_fixed(densenet_model,Validation_generator, Testing_generator_FST_V-VI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWwwGD_9W66O"
      },
      "outputs": [],
      "source": [
        "compute_odin_softmax_scores_fixed(densenet_model,Validation_generator, Testing_generator_FST_I-IV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yn-6mj2liPE0",
        "outputId": "40d0712c-c67e-4025-d589-19cb31dd76b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor(\"dense_4/BiasAdd:0\", shape=(?, 6), dtype=float32)\n",
            "Tensor(\"truediv_2:0\", shape=(?, 6), dtype=float32)\n",
            "Tensor(\"ArgMax_4:0\", shape=(1, ?), dtype=int64)\n",
            "\n",
            "===== Temperature: 200, Magnitude: 0.0002, Out-Distribution =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12222/12222 [2:11:44<00:00,  1.55it/s]\n"
          ]
        }
      ],
      "source": [
        "compute_odin_softmax_scores_fixed(densenet_model, Validation_generator, Testing_generator_ALL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBqdcdw7GfL0"
      },
      "source": [
        "## Baseline scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuFiMav1xDar",
        "outputId": "4fccac5e-9c48-4d5c-f602-15f27143b14e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Begin to compute baseline softmax scores\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        }
      ],
      "source": [
        "#lighter only\n",
        "compute_baseline_softmax_scores(densenet_model, Validation_generator, Testing_generator_FST_I-IV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzyOY-lIiiCA",
        "outputId": "f11e8e07-5915-40a8-b91b-2ddae0f86a9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Begin to compute baseline softmax scores\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        }
      ],
      "source": [
        "#darker only\n",
        "compute_baseline_softmax_scores(densenet_model, Validation_generator, Testing_generator_FST_V-VI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMXMzBJaivPi",
        "outputId": "dab6afcf-5d4c-41d1-95ba-d52a59857e3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Begin to compute baseline softmax scores\n"
          ]
        }
      ],
      "source": [
        "#ALL\n",
        "compute_baseline_softmax_scores(densenet_model, Validation_generator, Testing_generator_ALL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZHN1-1nQd_R"
      },
      "outputs": [],
      "source": [
        "#find the ptimal threshold:\n",
        "# Concatenate the scores and create corresponding labels\n",
        "\n",
        "scores_in = np.loadtxt(\"/content/densenet121_ODIN_200_0.0002_In_Darker.txt\")\n",
        "scores_out = np.loadtxt(\"/content/densenet121_ODIN_200_0.0002_Out_Darker.txt\")\n",
        "scores_D = np.concatenate([scores_in, scores_out])\n",
        "labels_D = np.concatenate([np.zeros(len(scores_in)), np.ones(len(scores_out))])\n",
        "\n",
        "    # Use ROC curve to find the optimal threshold\n",
        "fpr, tpr, thresholds = roc_curve(labels_D, scores_D)\n",
        "optimal_threshold_D = thresholds[np.argmax(tpr - fpr)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6G6zVBpUWNg",
        "outputId": "452a49d9-5be1-44eb-ad74-f95d9f0ebe6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.17385952174663544\n"
          ]
        }
      ],
      "source": [
        "print(optimal_threshold) #ODIN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCJXT0Ev-cgI",
        "outputId": "98ab2db5-05ea-4601-bec0-7137170d6771"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9962658286094666\n"
          ]
        }
      ],
      "source": [
        "print(optimal_threshold) #NN Softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tve8f5bZzung"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}